@article{pascanu2013revisiting,
  title =        {Revisiting natural gradient for deep networks},
  author =       {Pascanu, Razvan and Bengio, Yoshua},
  year =         2013
}

@article{johnson2002FaaDiBruno,
  title =        {The curious history of {F}a{\`a} di {B}runo's formula},
  author =       {Johnson, Warren P},
  journal =      {The American mathematical monthly},
  year =         2002,
}

@article{wei2018bdapch,
  title =        {{BDA-PCH}: Block-Diagonal Approximation of Positive-Curvature
                  {H}essian for Training Neural Networks},
  author =       {Chen, Sheng-Wei and Chou, Chun-Nan and Chang, Edward},
  year =         2018
}

@article{bakker2018OuterProductStructure,
  title =        {The Outer Product Structure of Neural Network Derivatives},
  author =       {Bakker, Craig and Henry, Michael J and Hodas, Nathan O},
  year =         2018,
}

@article{naumov2017HessianInMatrixForm,
  title =        {Feedforward and Recurrent Neural Networks Backward Propagation
                  and {H}essian in Matrix Form},
  author =       {Naumov, Maxim},
  year =         2017,
}

@article{mizutani2008secondorder,
  title =        {Second-Order Stagewise Backpropagation for {H}essian-Matrix
                  Analyses and Investigation of Negative Curvature},
  author =       {Mizutani, Eiji and Dreyfus, Stuart E},
  journal =      {Neural Networks},
  year =         2008,
}

@inproceedings{botev2017practical,
  title =        {Practical {G}auss-{N}ewton Optimisation for Deep Learning},
  author =       {Aleksandar Botev and Hippolyt Ritter and David Barber},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2017,
}

@inproceedings{martens2015optimizing,
  title =        {Optimizing Neural Networks with {K}ronecker-Factored
                  Approximate Curvature},
  author =       {James Martens and Roger Grosse},
  year =         2015,
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@inproceedings{grosse2016kronecker,
  title =        {A {K}ronecker-factored approximate {F}isher matrix for
                  convolution layers},
  author =       {Roger Grosse and James Martens},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2016,
}

@book{magnus1999MatrixDifferentialCalculus,
  title =        {{M}atrix {D}ifferential {C}alculus with {A}pplications in
                  {S}tatistics and {E}conometrics},
  author =       {Magnus, J. R. and Neudecker, H.},
  year =         1999,
}

@article{amari1998natural,
  title =        {Natural Gradient works Efficiently in Learning},
  author =       {Amari, Shun-Ichi},
  journal =      {Neural computation},
  year =         1998,
}

@incollection{paszke2019pytorch,
  title =        {{P}y{T}orch: {A}n Imperative Style, High-Performance Deep
                  Learning Library},
  author =       {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                  Adam and Bradbury, James and Chanan, Gregory and Killeen,
                  Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                  Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward
                  and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
                  Junjie and Chintala, Soumith},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2019,
}

@article{baydin2018automatic,
  author =       {Atilim Gunes Baydin and Barak A. Pearlmutter and Alexey
                  Andreyevich Radul and Jeffrey Mark Siskind},
  title =        {Automatic Differentiation in Machine Learning: {A} Survey},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2018,
}

@article{pearlmutter1994fast,
  author =       {Barak A. Pearlmutter},
  title =        {Fast Exact Multiplication by the {H}essian},
  journal =      {Neural Computation},
  year =         1994,
}

@inproceedings{glorot2011ReLU,
  title =        {Deep Sparse Rectifier Neural Networks},
  author =       {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2011
}

@inproceedings{he2016deep,
  title =        {Deep Residual Learning for Image Recognition},
  author =       {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun,
                  Jian},
  booktitle =    {IEEE Conference on Computer Vision and Pattern Recognition
                  (CVPR)},
  year =         2016
}

@inproceedings{mishkin2015GoodInit,
  title =        {All you need is a good Init},
  author =       {Mishkin, Dmytro and Matas, Jiri},
  year =         2015,
  booktitle =    {International Conference on Learning Representations (ICLR)}
}

@inproceedings{glorot2010XavierInit,
  title =        {Understanding the Difficulty of Training Deep Feedforward
                  Neural Networks},
  author =       {Glorot, Xavier and Bengio, Yoshua},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2010
}

@inproceedings{ioffe2015batch,
  title =        {Batch Normalization: Accelerating Deep Network Training by
                  Reducing Internal Covariate Shift},
  author =       {Ioffe, Sergey and Szegedy, Christian},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2015,
}

@incollection{zhang2018LocalHessianBackpropagation,
  title =        {On the Local {H}essian in Backpropagation},
  author =       {Zhang, Huishuai and Chen, Wei and Liu, Tie-Yan},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2018,
}

@article{ruder2016overviewGradientDescent,
  title =        {An Overview of Gradient Descent Optimization Algorithms},
  author =       {Ruder, Sebastian},
  year =         2016
}

@inproceedings{kingma2015adam,
  title =        {{A}dam: A Method for Stochastic Optimization},
  author =       {Kingma, Diederik P and Ba, Jimmy},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2015
}

@inproceedings{martens2010deep,
  title =        {Deep Learning via {H}essian-Free Optimization.},
  author =       {Martens, James},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2010,
}

@article{zhang2017blockdiagonal,
  title =        {Block-diagonal {H}essian-free Optimization for Training Neural
                  Networks},
  author =       {Zhang, Huishuai and Xiong, Caiming and Bradbury, James and
                  Socher, Richard},
  year =         2017,
}

@inproceedings{abadi2016tensorflow,
  title =        {{TensorFlow}: A System for Large-Scale Machine Learning},
  author =       {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen
                  and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay
                  Ghemawat and Geoffrey Irving and Michael Isard and Manjunath
                  Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and
                  Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay
                  Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and
                  Xiaoqiang Zheng},
  year =         2016,
  booktitle =    {USENIX Symposium on Operating Systems Design and
                  Implementation (OSDI)},
}

@techreport{krizhevsky2009learning,
  title =        {Learning multiple layers of features from tiny images},
  author =       {Krizhevsky, Alex},
  year =         2009,
}

@article{schraudolph2002fast,
  title =        {Fast Curvature Matrix-Vector Products for Second-Order
                  Gradient Descent},
  author =       {Nicol N. Schraudolph},
  journal =      {Neural Computation},
  year =         2002,
}

@inproceedings{schneider2019deepobs,
  title =        {Deep{OBS}: A Deep Learning Optimizer Benchmark Suite},
  author =       {Frank Schneider and Lukas Balles and Philipp Hennig},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2019,
}

@misc{goodfellow2010ConvolutionForAutoencoders,
  author =       {Goodfellow, Ian J.},
  title =        {Technical Report: Multidimensional, Downsampled Convolution
                  for Autoencoders},
  year =         2010,
}

@inproceedings{chellapilla2006HighPerformanceCNN,
  title =        {{High Performance Convolutional Neural Networks for Document
                  Processing}},
  author =       {Chellapilla, Kumar and Puri, Sidd and Simard, Patrice},
  booktitle =    {{International Workshop on Frontiers in Handwriting
                  Recognition}},
  year =         2006,
}

@article{dumoulin2016ConvolutionArithmeticGuide,
  title =        {A guide to convolution arithmetic for deep learning},
  author =       {Dumoulin, Vincent and Visin, Francesco},
  year =         2016
}

@article{bradbury2018jax,
  title =        {{JAX}: composable transformations of {P}ython + {N}um{P}y
                  programs},
  author =       {Bradbury, James and Frostig, Roy and Hawkins, Peter and
                  Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal
                  and Wanderman-Milne, Skye},
  year =         2018
}

@article{innes2018zygote,
  author =       {Michael Innes},
  title =        {Don't Unroll Adjoint: {D}ifferentiating {SSA}-Form Programs},
  year =         2018,
}

@article{innes2018flux,
  year =         2018,
  author =       {Michael Innes},
  title =        {Flux: {E}legant machine learning with {J}ulia},
  journal =      {Journal of Open Source Software}
}

@inproceedings{tokui2015chainer,
  author =       {Seiya Tokui and Kenta Oono and Shohei Hido and Justin Clayton},
  title =        {Chainer: {A} next-generation open source framework for deep
                  learning},
  year =         2015,
  booktitle =    {Neural Information Processing Systems (NIPS), Workshop on
                  Machine Learning Systems},
}

@inproceedings{chen2015mxnet,
  author =       {Tianqi Chen and Mu Li and Yutian Li and Min Lin and Naiyan
                  Wang and Minjie Wang and Tianjun Xiao and Bing Xu and Chiyuan
                  Zhang and Zheng Zhang},
  title =        {{MXNet}: {A} Flexible and Efficient Machine Learning Library
                  for Heterogeneous Distributed Systems},
  year =         2015,
  booktitle =    {Neural Information Processing Systems (NIPS), Workshop on
                  Machine Learning Systems},
}

@inproceedings{katharopoulos2018samples,
  author =       {Angelos Katharopoulos and Fran{\c{c}}ois Fleuret},
  title =        {Not All Samples Are Created Equal: {D}eep Learning with
                  Importance Sampling},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2018,
}

@article{bordes2009sgdqn,
  author =       {Antoine Bordes and L{\'{e}}on Bottou and Patrick Gallinari},
  title =        {{SGD-QN:} Careful Quasi-{N}ewton Stochastic Gradient Descent},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2009,
}

@inproceedings{tsuji2019performance,
  author =       {Yohei Tsuji and Kazuki Osawa and Yuichiro Ueno and Akira
                  Naruse and Rio Yokota and Satoshi Matsuoka},
  title =        {Performance Optimizations and Analysis of Distributed Deep
                  Learning with Approximated Second-Order Optimization Method},
  booktitle =    {International Conference on Parallel Processing, Workshop
                  Proceedings},
  year =         2019,
}

@inproceedings{kunstner2019limitations,
  author =       {Frederik Kunstner and Lukas Balles and Philipp Hennig},
  title =        {Limitations of the Empirical {F}isher Approximatiom},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2019,
}

@article{hochreither1997lstm,
  author =       {Sepp Hochreiter and J{\"{u}}rgen Schmidhuber},
  title =        {Long Short-Term Memory},
  journal =      {Neural Computation},
  year =         1997,
}

@inproceedings{springenberg2015striving,
  author =       {Jost Tobias Springenberg and Alexey Dosovitskiy and Thomas
                  Brox and Martin A. Riedmiller},
  title =        {Striving for Simplicity: {T}he All Convolutional Net},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2015,
}

@article{martens2014new,
  author =       {James Martens},
  title =        {New perspectives on the natural gradient method},
  year =         2014,
}

@article{rotem2018glow,
  author =       {Nadav Rotem and Jordan Fix and Saleem Abdulrasool and Summer
                  Deng and Roman Dzhabarov and James Hegeman and Roman
                  Levenstein and Bert Maher and Nadathur Satish and Jakob Olesen
                  and Jongsoo Park and Artem Rakhov and Misha Smelyanskiy},
  title =        {Glow: {G}raph Lowering Compiler Techniques for Neural
                  Networks},
  year =         2018,
}

@article{george2018fast,
  title =        {Fast Approximate Natural Gradient Descent in a
                  {Kronecker}-factored Eigenbasis},
  author =       {George, Thomas and Laurent, C{\'e}sar and Bouthillier, Xavier
                  and Ballas, Nicolas and Vincent, Pascal},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2018,
}

@article{mahsereci2017probabilistic,
  author =       {Maren Mahsereci and Philipp Hennig},
  title =        {Probabilistic Line Searches for Stochastic Optimization},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2017,
}

@inproceedings{balles2017coupling,
  author =       {Lukas Balles and Javier Romero and Philipp Hennig},
  title =        {Coupling Adaptive Batch Sizes with Learning Rates},
  booktitle =    {Conference on Uncertainty in Artificial Intelligence (UAI)},
  year =         2017,
}

@inproceedings{balles2018dissecting,
  author =       {Lukas Balles and Philipp Hennig},
  title =        {Dissecting {A}dam: {T}he Sign, Magnitude and Variance of
                  Stochastic Gradients},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2018,
}

@inproceedings{borsos2019online,
  author =       {Zal{\'{a}}n Borsos and Sebastian Curi and Kfir Yehuda Levy and
                  Andreas Krause},
  title =        {Online Variance Reduction with Mixtures},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2019,
}

@article{needel2016stochastic,
  author =       {Deanna Needell and Nathan Srebro and Rachel Ward},
  title =        {Stochastic gradient descent, weighted sampling, and the
                  randomized {K}aczmarz algorithm},
  journal =      {Mathematical Programming},
  year =         2016,
}

@inproceedings{deroos2019active,
  author =       {Filip de Roos and Philipp Hennig},
  title =        {Active Probabilistic Inference on Matrices for
                  Pre-Conditioning in Stochastic Optimization},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2019,
}

@inproceedings{leroux2007topmoumoute,
  author =       {Nicolas {Le Roux} and Pierre{-}Antoine Manzagol and Yoshua
                  Bengio},
  title =        {Topmoumoute Online Natural Gradient Algorithm},
  booktitle =    {Advances in Neural Information Processing Systems 20},
  year =         2007,
}

@inproceedings{leroux2010fast,
  author =       {Nicolas {Le Roux} and Andrew W. Fitzgibbon},
  title =        {A fast natural {N}ewton method},
  booktitle =    {Proceedings of the 27th International Conference on Machine
                  Learning},
  year =         2010,
}

@inproceedings{martens2018kronecker,
  author =       {James Martens and Jimmy Ba and Matt Johnson},
  title =        {{K}ronecker-factored Curvature Approximations for Recurrent
                  Neural Networks},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@article{goodfellow2015efficient,
  author =       {Ian J. Goodfellow},
  title =        {Efficient Per-Example Gradient Computations},
  year =         2015,
}

@inproceedings{becker1988improving,
  author =       {Sue Becker and Yann {Le Cun}},
  title =        {Improving the Convergence of Back-Propagation Learning with
                  Second Order Methods},
  booktitle =    {Connectionist Models Summer School},
  year =         1989,
}

@inproceedings{dangel2020modular,
  title =        { Modular Block-diagonal Curvature Approximations for
                  Feedforward Architectures},
  author =       {Dangel, Felix and Harmeling, Stefan and Hennig, Philipp},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2020,
}

@misc{gurari2018gradient,
  author =       {Guy Gur-Ari and Daniel A. Roberts and Ethan Dyer},
  title =        {{Gradient Descent Happens in a Tiny Subspace}},
  year =         2018,
}

@article{bengio2012neural,
  author =       {Yoshua {Bengio}},
  journal =      {Neural Networks},
  title =        {{Practical recommendations for gradient-based training of deep
                  architectures}},
  year =         2012,
}

@Misc{nagarajan2019generalization,
  author =       {Vaishnavh Nagarajan and J. Zico Kolter},
  title =        {{Generalization in Deep Networks: The Role of Distance from
                  Initialization}},
  year =         2019,
}

@InProceedings{chatterjee2020coherent,
  author =       {Satrajit Chatterjee},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{Coherent Gradients: An Approach to Understanding
                  Generalization in Gradient Descent-based Optimization}},
  year =         2020,
}

@Misc{chatterjee2020making,
  author =       {Satrajit Chatterjee and Piotr Zielinski},
  title =        {{Making Coherence Out of Nothing At All: Measuring the
                  Evolution of Gradient Alignment}},
  year =         2020,
}

@InProceedings{sankararaman2020impact,
  author =       {Sankararaman, Karthik Abinav and De, Soham and Xu, Zheng and
                  Huang, W. Ronny and Goldstein, Tom},
  booktitle =    {International Conference on Machine Learning (ICML)},
  title =        {{The Impact of Neural Network Overparameterization on Gradient
                  Confusion and Stochastic Gradient Descent}},
  year =         2020,
}

@Article{schmidt2014convergence,
  author =       {Schmidt, Mark},
  title =        {{Convergence rate of stochastic gradient with constant step
                  size}},
  year =         2014,
}

@Misc{agrawal2020investigating,
  author =       {Ayush Manish Agrawal and Atharva Tendle and Harshvardhan Sikka
                  and Sahib Singh and Amr Kayid},
  title =        {{Investigating Learning in Deep Neural Networks using
                  Layer-Wise Weight Change}},
  year =         2020,
}

@Misc{thompson2020computational,
  author =       {Neil C. Thompson and Kristjan Greenewald and Keeheon Lee and
                  Gabriel F. Manso},
  title =        {{The Computational Limits of Deep Learning}},
  year =         2020,
}

@InProceedings{frankle2020early,
  author =       {Jonathan Frankle and David J. Schwab and Ari S. Morcos},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{The Early Phase of Neural Network Training}},
  year =         2020,
}

@Misc{ginsburg2020regularization,
  author =       {Boris Ginsburg},
  title =        {{On regularization of gradient descent, layer imbalance and
                  flat minima}},
  year =         2020,
}

@InProceedings{mulayoff2020unique,
  author =       {Rotem Mulayoff and Tomer Michaeli},
  booktitle =    {International Conference on Machine Learning (ICML)},
  title =        {{Unique Properties of Flat Minima in Deep Networks}},
  year =         2020,
}

@InProceedings{ghorbani2019investigation,
  author =       {Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
  booktitle =    {International Conference on Machine Learning (ICML)},
  title =        {{An Investigation into Neural Net Optimization via Hessian
                  Eigenvalue Density}},
  year =         2019,
}

@Misc{sagun2017eigenvalues,
  author =       {Levent Sagun and Leon Bottou and Yann LeCun},
  title =        {{Eigenvalues of the Hessian in Deep Learning: Singularity and
                  Beyond}},
  year =         2017,
}

@Misc{sagun2018empirical,
  author =       {Levent Sagun and Utku Evci and V. Ugur Guney and Yann Dauphin
                  and Leon Bottou},
  title =        {{Empirical Analysis of the Hessian of Over-Parametrized Neural
                  Networks}},
  year =         2018,
}

@Article{takeuchi1976distribution,
  author =       {Takeuchi, Kei},
  journal =      {Mathematical Science},
  title =        {{The distribution of information statistics and the criterion
                  of goodness of fit of models}},
  year =         1976,
}

@InProceedings{thomas2020interplay,
  author =       {Thomas, Valentin and Pedregosa, Fabian and van Merri\"enboer,
                  Bart and Manzagol, Pierre-Antoine and Bengio, Yoshua and Roux,
                  Nicolas Le},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  title =        {{On the interplay between noise and curvature and its effect
                  on optimization and generalization}},
  year =         2020,
}

@Article{warsa2004krylov,
  author =       {Warsa, James and Wareing, Todd and Morel, Jim and Mcghee, John
                  and Lehoucq, Richard},
  journal =      {Nuclear Science and Engineering},
  title =        {{Krylov Subspace Iterations for Deterministic k-Eigenvalue
                  Calculations}},
  year =         2004,
}

@InProceedings{yao2020pyhessian,
  author =       {Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney,
                  Michael W.},
  booktitle =    {IEEE International Conference on Big Data},
  title =        {{PyHessian: Neural Networks Through the Lens of the Hessian}},
  year =         2020,
}

@InProceedings{jastrzebski2020break,
  author =       {Stanislaw Jastrzebski and Maciej Szymczak and Stanislav Fort
                  and Devansh Arpit and Jacek Tabor and Kyunghyun Cho and
                  Krzysztof Geras},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{The Break-Even Point on Optimization Trajectories of Deep
                  Neural Networks}},
  year =         2020,
}

@InProceedings{liu2020understanding,
  author =       {Jinlong Liu and Yunzhi Bai and Guoqing Jiang and Ting Chen and
                  Huayan Wang},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{Understanding Why Neural Networks Generalize Well Through
                  GSNR of Parameters}},
  year =         2020,
}

@Misc{mahsereci2017early,
  author =       {Maren Mahsereci and Lukas Balles and Christoph Lassner and
                  Philipp Hennig},
  title =        {{Early Stopping without a Validation Set}},
  year =         2017,
}

@Misc{bahamou2019dynamic,
  author =       {Achraf Bahamou and Donald Goldfarb},
  title =        {{A Dynamic Sampling Adaptive-{SGD} Method for Machine
                  Learning}},
  year =         2019,
}

@Article{bollapragada2017adaptive,
  author =       {Raghu Bollapragada and Richard H. Byrd and Jorge Nocedal},
  journal =      {SIAM Journal on Optimization},
  title =        {{Adaptive Sampling Strategies for Stochastic Optimization}},
  year =         2017,
}

@Article{byrd2012sample,
  author =       {Byrd, Richard H. and Chin, Gillian M. and Nocedal, Jorge and
                  Wu, Yuchen},
  journal =      {Mathematicl Programming},
  title =        {{Sample Size Selection in Optimization Methods for Machine
                  Learning}},
  year =         2012,
}

@Misc{faghri2020study,
  author =       {Fartash Faghri and David Duvenaud and David J. Fleet and Jimmy
                  Ba},
  title =        {{A Study of Gradient Variance in Deep Learning}},
  year =         2020,
}

@InProceedings{dangel2020backpack,
  author =       {Felix Dangel and Frederik Kunstner and Philipp Hennig},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{BackPACK: Packing more into Backprop}},
  year =         2020,
}

@Misc{xing2018walk,
  author =       {Chen Xing and Devansh Arpit and Christos Tsirigotis and Yoshua
                  Bengio},
  title =        {{A Walk with SGD}},
  year =         2018,
}

@Article{wu2018understanding,
  author =       {Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger
                  B.},
  journal =      {International Conference on Learning Representations (ICLR)},
  title =        {{Understanding short-horizon bias in stochastic
                  meta-optimization}},
  year =         2018,
}

@InProceedings{keskar2017large,
  author =       {Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal
                  and Mikhail Smelyanskiy and Ping Tak Peter Tang},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{On Large-Batch Training for Deep Learning: Generalization Gap
                  and Sharp Minima}},
  year =         2017,
}

@InProceedings{dinh2017sharp,
  author =       {Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua
                  Bengio},
  booktitle =    {International Conference on Machine Learning (ICML)},
  title =        {{Sharp Minima Can Generalize For Deep Nets}},
  year =         2017,
}

@Article{hochreiter1997flat,
  author =       {Sepp Hochreiter and J{\"{u}}rgen Schmidhuber},
  journal =      {Neural Computation},
  title =        {{Flat Minima}},
  year =         1997,
}

@Article{harris2020array,
  author =       {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                  van der Walt and Ralf Gommers and Pauli Virtanen and David
                  Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                  Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                  and Stephan Hoyer and Marten H. van Kerkwijk and Matthew Brett
                  and Allan Haldane and Jaime Fern{\'{a}}ndez del R{\'{i}}o and
                  Mark Wiebe and Pearu Peterson and Pierre G{\'{e}}rard-Marchant
                  and Kevin Sheppard and Tyler Reddy and Warren Weckesser and
                  Hameer Abbasi and Christoph Gohlke and Travis E. Oliphant},
  journal =      {Nature},
  title =        {Array programming with {NumPy}},
  year =         2020,
}

@InProceedings{lecun1998gradient,
  author =       {Yann Lecun and Léon Bottou and Yoshua Bengio and Patrick
                  Haffner},
  booktitle =    {Proceedings of the IEEE},
  title =        {{Gradient-based learning applied to document recognition}},
  year =         1998,
}

@InProceedings{deng2009imagenet,
  author =       {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and
                  Li, Kai and Fei-Fei, Li},
  title =        {{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle =    {IEEE conference on computer vision and pattern recognition
                  (CVPR)},
  year =         2009,
}

@InProceedings{vaswani2019painless,
  author =       {Vaswani, Sharan and Mishkin, Aaron and Laradji, Issam and
                  Schmidt, Mark and Gidel, Gauthier and Lacoste-Julien, Simon},
  booktitle =    {Neural Information Processing Systems (NeurIPS)},
  title =        {{Painless Stochastic Gradient: Interpolation, Line-Search, and
                  Convergence Rates}},
  year =         2019,
}

@Misc{biewald2020experiment,
  author =       {Biewald, Lukas},
  title =        {{Experiment Tracking with Weights and Biases}},
  year =         2020,
}

@InProceedings{jastrzebski2021catastrophic,
  title =        {Catastrophic Fisher Explosion: Early Phase Fisher Matrix
                  Impacts Generalization},
  author =       {Jastrzebski, Stanislaw and Arpit, Devansh and Astrand, Oliver
                  and Kerg, Giancarlo B and Wang, Huan and Xiong, Caiming and
                  Socher, Richard and Cho, Kyunghyun and Geras, Krzysztof J},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2021,
}

@Misc{xiao2017fashion,
  author =       {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title =        {{Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine
                  Learning Algorithms}},
  year =         2017,
}

@Misc{netzer2011reading,
  author =       {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco,
                  Alessandro and Wu, Bo and Ng, Andrew Y.},
  booktitle =    {Neural Information Processing System (NIPS), Workshop on Deep
                  Learning and Unsupervised Feature Learning},
  title =        {{Reading Digits in Natural Images with Unsupervised Feature
                  Learning}},
  year =         2011,
}

@InProceedings{simonyan2015deep,
  author =       {Simonyan, Karen and Zisserman, Andrew},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  title =        {{Very Deep Convolutional Networks for Large-Scale Image
                  Recognition}},
  year =         2015,
}

@inproceedings{lecun1993automatic,
  author =       {LeCun, Yann and Simard, Patrice and Pearlmutter, Barak},
  booktitle =    {Neural Information Processing Systems (NIPS)},
  title =        {Automatic Learning Rate Maximization by On-Line Estimation of
                  the Hessian\textquotesingle s Eigenvectors},
  year =         1993
}

@inproceedings{daxberger2021laplace,
  title =        {Laplace Redux--Effortless {B}ayesian Deep Learning},
  author =       {Erik Daxberger and Agustinus Kristiadi and Alexander Immer and
                  Runa Eschenhagen and Matthias Bauer and Philipp Hennig},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2021
}

@misc{nakatsukasa2019lowrank,
  title =        {The low-rank eigenvalue problem},
  author =       {Yuji Nakatsukasa},
  year =         2019,
}

@misc{yao2021adahessian,
  title =        {ADAHESSIAN: An Adaptive Second Order Optimizer for Machine
                  Learning},
  author =       {Zhewei Yao and Amir Gholami and Sheng Shen and Mustafa Mustafa
                  and Kurt Keutzer and Michael W. Mahoney},
  year =         2021,
}

@misc{gargiani2020promise,
  title =        {On the Promise of the Stochastic Generalized {G}auss-{N}ewton
                  Method for Training {DNN}s},
  author =       {Matilde Gargiani and Andrea Zanelli and Moritz Diehl and Frank
                  Hutter},
  year =         2020,
}

@inproceedings{schneider2021cockpit,
  title =        {{Cockpit: A Practical Debugging Tool for Training Deep Neural
                  Networks}},
  author =       {Frank Schneider and Felix Dangel and Philipp Hennig},
  year =         2021,
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
}

@conference{schmidt2021descending,
  title =        {Descending through a Crowded Valley - Benchmarking Deep
                  Learning Optimizers},
  author =       {Schmidt, R. M. and Schneider, F. and Hennig, P.},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2021,
}

@inproceedings{osawa2019large,
  author =       {Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse,
                  Akira and Yokota, Rio and Matsuoka, Satoshi},
  booktitle =    {IEEE Conference on Computer Vision and Pattern Recognition
                  (CVPR)},
  title =        {Large-Scale Distributed Second-Order Optimization Using
                  {K}ronecker-Factored Approximate Curvature for Deep
                  Convolutional Neural Networks},
  year =         2019,
}

@inproceedings{singh2020woodfisher,
  author =       {Singh, Sidak Pal and Alistarh, Dan},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  title =        {{WoodFisher}: Efficient Second-Order Approximation for Neural
                  Network Compression},
  year =         2020
}

@misc{granziol2021deep,
  title =        {Deep Curvature Suite},
  author =       {Diego Granziol and Xingchen Wan and Timur Garipov},
  year =         2021,
}

@misc{papyan2019spectrum,
  title =        {The Full Spectrum of Deepnet {H}essians at Scale: Dynamics
                  with {SGD} Training and Sample Size},
  author =       {Vardan Papyan},
  year =         2019,
}

@misc{adams2018estimating,
  title =        {Estimating the Spectral Density of Large Implicit Matrices},
  author =       {Ryan P. Adams and Jeffrey Pennington and Matthew J. Johnson
                  and Jamie Smith and Yaniv Ovadia and Brian Patton and James
                  Saunderson},
  year =         2018,
}

@article{byrd2011use,
  author =       {Byrd, Richard H. and Chin, Gillian M. and Neveitt, Will and
                  Nocedal, Jorge},
  title =        {On the Use of Stochastic {H}essian Information in Optimization
                  Methods for Machine Learning},
  journal =      {SIAM Journal on Optimization},
  year =         2011,
}

@inproceedings{ritter2018scalable,
  title =        {A Scalable {L}aplace Approximation for Neural Networks},
  author =       {Hippolyt Ritter and Aleksandar Botev and David Barber},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@inproceedings{ritter2018online,
  author =       {Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  title =        {Online Structured {L}aplace Approximations for Overcoming
                  Catastrophic Forgetting},
  year =         2018
}

@inproceedings{kristiadi2020being,
  title =        {Being {B}ayesian, even just a bit, fixes overconfidence in
                  {ReLU} networks},
  author =       {Kristiadi, Agustinus and Hein, Matthias and Hennig, Philipp},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2020,
}

@inproceedings{papyan2019measurements,
  author =       {Vardan Papyan},
  title =        {Measurements of Three-Level Hierarchical Structure in the
                  Outliers in the Spectrum of Deepnet {H}essians},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2019,
}

@misc{cai2020gramgaussnewton,
  title =        {Gram-Gauss-Newton Method: Learning Overparameterized Neural
                  Networks for Regression Problems},
  author =       {Tianle Cai and Ruiqi Gao and Jikai Hou and Siyu Chen and Dong
                  Wang and Di He and Zhihua Zhang and Liwei Wang},
  year =         2020,
}

@article{chen2021fast,
  author =       {Chen, Chao and Reiz, Severin and Yu, Chenhan D. and Bungartz,
                  Hans-Joachim and Biros, George},
  title =        {Fast Approximation of the {G}auss--{N}ewton {H}essian Matrix
                  for the Multilayer Perceptron},
  journal =      {SIAM Journal on Matrix Analysis and Applications},
  year =         2021,
}

@article{efron1979bootstrap,
  author =       {Efron, Bradley},
  title =        {Bootstrap Methods: Another Look at the Jackknife},
  journal =      {The Annals of Statistics},
  year =         1979,
}

@misc{idelbayev2018proper,
  author =       "Yerlan Idelbayev",
  title =        "Proper {ResNet} Implementation for {CIFAR10/CIFAR100} in
                  {PyTorch}",
  year =         2018,
}

@book{goodfellow2016deep,
  Title =        {Deep Learning},
  Author =       {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  Year =         2016,
}

@article{ollivier2011information,
  author =       {Ollivier, Yann and Arnold, Ludovic and Auger, Anne and Hansen,
                  Nikolaus},
  title =        {Information-Geometric Optimization Algorithms: A Unifying
                  Picture via Invariance Principles},
  year =         2011,
}

@article{bottou2016machine,
  author =       {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
  title =        {Optimization Methods for Large-Scale Machine Learning},
  year =         2016,
}

@inproceedings{oktay2021randomized,
  title =        {Randomized Automatic Differentiation},
  author =       {Deniz Oktay and Nick McGreivy and Joshua Aduol and Alex
                  Beatson and Ryan P Adams},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2021,
}

@misc{dangel2021vivit,
  title =        {{ViViT}: {C}urvature access through the generalized
                  {G}auss-{N}ewton's low-rank structure},
  author =       {Felix Dangel and Lukas Tatzel and Philipp Hennig},
  year =         2021,
}

@book{cormen2001introduction,
  author =       {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald
                  L. and Stein, Clifford},
  title =        {Introduction to Algorithms},
  year =         2001
}

@article{naumann2008optimal,
  author =       {Naumann, Uwe},
  title =        {Optimal Jacobian Accumulation is NP-Complete},
  year =         2008,
  journal =      {Mathematical Programming},
}

@incollection{rumelhart1986learning,
  author =       {Rumelhart, David E. and Hinton, Geoffrey E. and Williams,
                  Ronald J.},
  booktitle =    {Parallel Distributed Processing: Explorations in the
                  Microstructure of Cognition, {V}olume 1: {F}oundations},
  title =        {Learning Internal Representations by Error Propagation},
  year =         1986
}

@misc{frostig2021decomposing,
  author =       {Frostig, Roy and Johnson, Matthew J. and Maclaurin, Dougal and
                  Paszke, Adam and Radul, Alexey},
  title =        {Decomposing reverse-mode automatic differentiation},
  year =         2021,
}

@misc{radul2022you,
  author =       {Radul, Alexey and Paszke, Adam and Frostig, Roy and Johnson,
                  Matthew and Maclaurin, Dougal},
  title =        {You Only Linearize Once: Tangents Transpose to Gradients},
  year =         2022,
}

@inproceedings{henriques2019small,
  author =       {Henriques, João F. and Ehrhardt, Sebastien and Albanie, Samuel
                  and Vedaldi, Andrea},
  title =        {Small Steps and Giant Leaps: Minimal Newton Solvers for Deep
                  Learning},
  booktitle =    {International Conference on Computer Vision (ICCV)},
  year =         2019
}

@article{papyan2020traces,
  author =       {Vardan Papyan},
  title =        {Traces of Class/Cross-Class Structure Pervade Deep Learning
                  Spectra},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2020,
}

@inproceedings{lecun1889optimal,
  author =       {LeCun, Yann and Denker, John and Solla, Sara},
  booktitle =    {Neural Information Processing Systems (NIPS)},
  title =        {Optimal Brain Damage},
  year =         1989
}

@inproceedings{hassibi1992second,
  author =       {Hassibi, Babak and Stork, David},
  booktitle =    {Advances in Neural Information Processing Systems (NIPS)},
  title =        {Second order derivatives for network pruning: Optimal Brain
                  Surgeon},
  year =         1992
}

@inproceedings{zhao2015stochastic,
  title =        {Stochastic Optimization with Importance Sampling for
                  Regularized Loss Minimization},
  author =       {Zhao, Peilin and Zhang, Tong},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2015,
}

@inproceedings{needell2014stochastic,
  author =       {Needell, Deanna and Ward, Rachel and Srebro, Nati},
  booktitle =    {Advances in Neural Information Processing Systems (NIPS)},
  title =        {Stochastic Gradient Descent, Weighted Sampling, and the
                  Randomized {K}aczmarz algorithm},
  year =         2014
}

@article{wang2017accelerating,
  title =        {Accelerating Deep Neural Network Training with Inconsistent
                  Stochastic Gradient Descent},
  author =       {Linnan Wang and Yi Yang and Martin Renqiang Min and Srimat T.
                  Chakradhar},
  journal =      {Neural networks},
  year =         2017,
}

@inproceedings{abadi2016deep,
  author =       {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan,
                  H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  title =        {Deep Learning with Differential Privacy},
  year =         2016,
  booktitle =    {ACM SIGSAC Conference on Computer and Communications Security},
}

@inproceedings{fredrikson2015model,
  title =        {Model Inversion Attacks That Exploit Confidence Information
                  and Basic Countermeasures},
  year =         2015,
  author =       {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  booktitle =    {ACM Conference on Computer and Communications Security (CCS)}
}

@inproceedings{shokri2015privacy,
  author =       {Shokri, Reza and Shmatikov, Vitaly},
  title =        {Privacy-Preserving Deep Learning},
  year =         2015,
  booktitle =    {ACM SIGSAC Conference on Computer and Communications Security},
}

@article{robbins1951stochastic,
  author =       {Herbert Robbins and Sutton Monro},
  title =        {{A Stochastic Approximation Method}},
  journal =      {The Annals of Mathematical Statistics},
  year =         1951,
}

@article{polyak1964some,
  title =        {Some methods of speeding up the convergence of iteration
                  methods},
  journal =      {USSR Computational Mathematics and Mathematical Physics},
  year =         1964,
  author =       {B.T. Polyak},
}

@article{nesterov1983method,
  title =        {A method for solving the convex programming problem with
                  convergence rate $O(1/k^2)$},
  author =       {Yurii Nesterov},
  journal =      {Proceedings of the USSR Academy of Sciences},
  year =         1983,
}

@article{duchi2011adaptive,
  author =       {John Duchi and Elad Hazan and Yoram Singer},
  title =        {Adaptive Subgradient Methods for Online Learning and
                  Stochastic Optimization},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2011,
}

@article{tieleman2012lecture,
  title =        {Lecture 6.5-rmsprop: Divide the gradient by a running average
                  of its recent magnitude},
  author =       {Tieleman, Tijmen and Hinton, Geoffrey and others},
  journal =      {COURSERA: Neural networks for machine learning},
  year =         2012
}

@article{zeiler2012adadelta,
  author =       {Zeiler, Matthew},
  year =         2012,
  title =        {ADADELTA: An adaptive learning rate method},
}

@inproceedings{reddi2018on,
  title =        {On the Convergence of Adam and Beyond},
  author =       {Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@misc{choi2020on,
  title =        {On Empirical Comparisons of Optimizers for Deep Learning},
  author =       {Dami Choi and Christopher J. Shallue and Zachary Nado and
                  Jaehoon Lee and Chris J. Maddison and George E. Dahl},
  year =         2020,
}

@article{rosenblatt1958perceptron,
  title =        {The perceptron: a probabilistic model for information storage
                  and organization in the brain.},
  author =       {Frank Rosenblatt},
  journal =      {Psychological Review},
  year =         1958,
}

@inproceedings{so2021searching,
  title =        {Searching for Efficient Transformers for Language Modeling},
  author =       {David So and Wojciech Ma{\'n}ke and Hanxiao Liu and Zihang Dai
                  and Noam Shazeer and Quoc V Le},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2021,
}

@article{wu2019group,
  title =        {Group Normalization},
  author =       {Yuxin Wu and Kaiming He},
  journal =      {International Journal of Computer Vision},
  year =         2019,
}

@inproceedings{vaswani2017attention,
  author =       {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and
                  Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  title =        {Attention is All you Need},
  year =         2017
}

@article{cho2014properties,
  author =       {Cho, Kyunghyun and Merrienboer, Bart and Bahdanau, Dzmitry and
                  Bengio, Y.},
  year =         2014,
  title =        {On the Properties of Neural Machine Translation:
                  Encoder-Decoder Approaches},
}

@article{elman1990finding,
  title =        {Finding structure in time},
  journal =      {Cognitive Science},
  year =         1990,
  author =       {Jeffrey L. Elman},
}

@inproceedings{krizhevsky2012imagenet,
  author =       {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle =    {Neural Information Processing Systems (NIPS)},
  title =        {ImageNet Classification with Deep Convolutional Neural
                  Networks},
  year =         2012
}

@InProceedings{zeiler2012visualizing,
  author =       "Zeiler, Matthew D. and Fergus, Rob",
  title =        "Visualizing and Understanding Convolutional Networks",
  booktitle =    "European Conference on Computer Vision (ECCV)",
  year =         2014,
}

@INPROCEEDINGS{szegedy2015going,
  author =       {Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet,
                  Pierre and Reed, Scott and Anguelov, Dragomir and Erhan,
                  Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle =    {IEEE Conference on Computer Vision and Pattern Recognition
                  (CVPR)},
  title =        {Going deeper with convolutions},
  year =         2015,
}

@inproceedings{choi2020starganv2,
  title =        {Star{GAN} v2: Diverse Image Synthesis for Multiple Domains},
  author =       {Yunjey Choi and Youngjung Uh and Jaejun Yoo and Jung-Woo Ha},
  booktitle =    {IEEE Conference on Computer Vision and Pattern Recognition
                  (CVPR)},
  year =         2020
}

@inproceedings{goodfellow2014generative,
  author =       {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and
                  Xu, Bing and Warde-Farley, David and Ozair, Sherjil and
                  Courville, Aaron and Bengio, Yoshua},
  booktitle =    {Neural Information Processing Systems (NIPS)},
  title =        {Generative Adversarial Nets},
  year =         2014
}

@inproceedings{karras2018progressive,
  title =        {Progressive Growing of {GAN}s for Improved Quality, Stability,
                  and Variation},
  author =       {Tero Karras and Timo Aila and Samuli Laine and Jaakko
                  Lehtinen},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@InProceedings{ramesh2021zero,
  title =        {Zero-Shot Text-to-Image Generation},
  author =       {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray,
                  Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and
                  Sutskever, Ilya},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2021,
}

@article{silver2018general,
  author =       {David Silver and Thomas Hubert and Julian Schrittwieser and
                  Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc
                  Lanctot and Laurent Sifre and Dharshan Kumaran and Thore
                  Graepel and Timothy Lillicrap and Karen Simonyan and Demis
                  Hassabis },
  title =        {A general reinforcement learning algorithm that masters chess,
                  shogi, and Go through self-play},
  journal =      {Science},
  year =         2018,
}

@article{mnih2013playing,
  author =       {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and
                  Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and
                  Riedmiller, Martin},
  year =         2013,
  month =        12,
  title =        {Playing Atari with Deep Reinforcement Learning}
}

@article{silver2016mastering,
  author =       {Silver, David and Huang, Aja and Maddison, Chris J. and Guez,
                  Arthur and Sifre, Laurent and van den Driessche, George and
                  Schrittwieser, Julian and Antonoglou, Ioannis and
                  Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander
                  and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and
                  Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine
                  and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  journal =      {Nature},
  title =        {Mastering the Game of {Go} with Deep Neural Networks and Tree
                  Search},
  year =         2016
}

@article{bahdanau2014neural,
  title =        {Neural machine translation by jointly learning to align and
                  translate},
  author =       {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  year =         2014
}

@article{luong2015effective,
  title =        {Effective approaches to attention-based neural machine
                  translation},
  author =       {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  year =         2015
}

@article{wu2016google,
  title =        {Google's neural machine translation system: Bridging the gap
                  between human and machine translation},
  author =       {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc
                  V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun,
                  Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and
                  others},
  year =         2016
}

@inproceedings{jouppi2017in,
  author =       {Jouppi, Norman P. and Young, Cliff and Patil, Nishant and
                  Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and
                  Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers,
                  Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford
                  and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau,
                  Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara
                  Vazir and Gottipati, Rajendra and Gulland, William and
                  Hagmann, Robert and Ho, C. Richard and Hogberg, Doug and Hu,
                  John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and
                  Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and
                  Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and
                  Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James
                  and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke,
                  Kyle and Lundin, Alan and MacKean, Gordon and Maggiore,
                  Adriana and Mahony, Maire and Miller, Kieran and Nagarajan,
                  Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and
                  Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and
                  Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir
                  and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and
                  Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing,
                  Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and
                  Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter,
                  Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
  title =        {In-Datacenter Performance Analysis of a Tensor Processing
                  Unit},
  booktitle =    {Annual International Symposium on Computer Architecture},
}

@inproceedings{kirk2007nvidia,
  author =       {Kirk, David},
  year =         2007,
  title =        {NVIDIA {CUDA} software and {GPU} parallel computing
                  architecture},
}

@article{radford2019language,
  title =        {Language Models are Unsupervised Multitask Learners},
  author =       {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David
                  and Amodei, Dario and Sutskever, Ilya},
  year =         2019
}

@article{brown2020language,
  title =        {Language Models are Few-Shot Learners},
  author =       {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie
                  Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind
                  Neelakantan and Pranav Shyam and Girish Sastry and Amanda
                  Askell and Sandhini Agarwal and Ariel Herbert-Voss and
                  Gretchen Krueger and Tom Henighan and Rewon Child and Aditya
                  Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter
                  and Christopher Hesse and Mark Chen and Eric Sigler and
                  Mateusz Litwin and Scott Gray and Benjamin Chess and Jack
                  Clark and Christopher Berner and Sam McCandlish and Alec
                  Radford and Ilya Sutskever and Dario Amodei},
  year =         2020,
}

@InProceedings{lin2014microsoft,
  author =       "Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays,
                  James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r,
                  Piotr and Zitnick, C. Lawrence",
  title =        "Microsoft COCO: Common Objects in Context",
  booktitle =    "European Conference on Computer Vision (ECCV)",
  year =         2014,
}

@article{hughes1989functional,
  author =       {J. Hughes},
  title =        {{Why Functional Programming Matters}},
  journal =      {Computer Journal},
  year =         1989
}

@misc{he2021functorch,
  author =       {Horace He, Richard Zou},
  title =        {functorch: {JAX}-like composable function transforms for
                  {P}y{T}orch},
  year =         2021
}

@book{fischer2010history,
  title =        {A History of the Central Limit Theorem: From Classical to
                  Modern Probability Theory},
  author =       {Fischer, Hans},
  booktitle =    {Sources and Studies in the History of {M}athematics and
                  {P}hysical Sciences},
  year =         2010,
}

@article{laplace1774memoire,
  title =        {M{\'e}moire sur la probabilit{\'e} de causes par les
                  {\'e}venements},
  author =       {Laplace, Pierre Simon},
  journal =      {M{\'e}moire de l'acad{\'e}mie royale des sciences},
  year =         1774
}

@inproceedings{saxe2014exact,
  author =       {Andrew M. Saxe and James L. McClelland and Surya Ganguli},
  title =        {Exact solutions to the nonlinear dynamics of learning in deep
                  linear neural networks},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2014,
}

@inproceedings{bernacchia2018exact,
  author =       {Bernacchia, Alberto and Lengyel, Mate and Hennequin,
                  Guillaume},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS},
  title =        {Exact natural gradient in deep linear networks and its
                  application to the nonlinear case},
  year =         2018,
}

@misc{wiki2022toeplitz,
  author =       "Wikipedia",
  title =        "{Toeplitz matrix}",
  year =         2022,
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Toeplitz_matrix&oldid=1094551484}},
  note =         "(online) accessed August 11"
}

@article{russakovsky2015imagenet,
  title =        {Imagenet large scale visual recognition challenge},
  author =       {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause,
                  Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng
                  and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael
                  and others},
  journal =      {International journal of computer vision},
  year =         2015,
}

@article{srivastava2014dropout,
  author =       {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and
                  Ilya Sutskever and Ruslan Salakhutdinov},
  title =        {Dropout: A Simple Way to Prevent Neural Networks from
                  Overfitting},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2014,
}

@article{bauer1974computational,
  author =       {Bauer, Friedrich L.},
  title =        {Computational Graphs and Rounding Error},
  journal =      {SIAM Journal on Numerical Analysis},
  year =         1974,
}

@article{griewank2012invented,
  title =        {Who invented the reverse mode of differentiation?},
  author =       {Griewank, Andreas},
  journal =      {Documenta Mathematica},
  year =         2012
}

@article{linnainmaa1976taylor,
  title =        {Taylor expansion of the accumulated rounding error},
  author =       {Linnainmaa, Seppo},
  journal =      {BIT Numerical Mathematics},
  year =         1976,
}

@article{balles2022noise,
  title =        {Noise-Aware Stochastic Optimization},
  author =       {Balles, Lukas},
  year =         2022,
  note =         {PhD thesis}
}

@InProceedings{immer2021scalable,
  title =        {Scalable Marginal Likelihood Estimation for Model Selection in
                  Deep Learning},
  author =       {Immer, Alexander and Bauer, Matthias and Fortuin, Vincent and
                  R{\"a}tsch, Gunnar and Emtiyaz, Khan Mohammad},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2021,
}

@article{theis2018faster,
  author =       {Theis, Lucas and Korshunova, Iryna and Tejani, Alykhan and
                  Huszár, Ferenc},
  year =         2018,
  title =        {Faster gaze prediction with dense networks and Fisher pruning}
}

@inproceedings{zeng2018mlprune,
  title =        {{MLP}rune: Multi-Layer Pruning for Automated Neural Network
                  Compression},
  author =       {Wenyuan Zeng and Raquel Urtasun},
  year =         2018
}

@inproceedings{dong2017learning,
  author =       {Dong, Xin and Chen, Shangyu and Pan, Sinno},
  booktitle =    {Advances in Neural Information Processing Systems (NIPS)},
  title =        {Learning to Prune Deep Neural Networks via Layer-wise Optimal
                  Brain Surgeon},
  year =         2017
}

@article{blalock2020state,
  title =        {What is the state of neural network pruning?},
  author =       {Blalock, Davis and Gonzalez Ortiz, Jose Javier and Frankle,
                  Jonathan and Guttag, John},
  journal =      {Proceedings of machine learning and systems},
  year =         2020
}

@article{dwork2014algorithmic,
  title =        {The algorithmic foundations of differential privacy},
  author =       {Dwork, Cynthia and Roth, Aaron and others},
  journal =      {Foundations and Trends in Theoretical Computer Science},
  year =         2014,
}

@article{fedus2022switch,
  author =       {William Fedus and Barret Zoph and Noam Shazeer},
  title =        {Switch Transformers: Scaling to Trillion Parameter Models with
                  Simple and Efficient Sparsity},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2022,
}

@article{loan2000ubiquitous,
  title =        {The ubiquitous {K}ronecker product},
  journal =      {Journal of Computational and Applied Mathematics},
  year =         2000,
  author =       {Charles F.Van Loan},
}

@misc{sankaran2022benchmarking,
  title =        {Benchmarking the Linear Algebra Awareness of {T}ensor{F}low
                  and {P}y{T}orch},
  author =       {Aravind Sankaran and Navid Akbari Alashti and Christos Psarras
                  and Paolo Bientinesi},
  year =         2022,
}

@inproceedings{immer2021improving,
  title =        { Improving predictions of {B}ayesian neural nets via local
                  linearization },
  author =       {Immer, Alexander and Korzepa, Maciej and Bauer, Matthias},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2021,
}

@inproceedings{gulrajani2021in,
  title =        {In Search of Lost Domain Generalization},
  author =       {Ishaan Gulrajani and David Lopez-Paz},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2021,
}

@inproceedings{yousefpour2021opacus,
  title =        {Opacus: User-Friendly Differential Privacy Library in PyTorch},
  author =       {Ashkan Yousefpour and Igor Shilov and Alexandre Sablayrolles
                  and Davide Testuggine and Karthik Prasad and Mani Malek and
                  John Nguyen and Sayan Ghosh and Akash Bharadwaj and Jessica
                  Zhao and Graham Cormode and Ilya Mironov},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS),
                  Workshop Privacy in Machine Learning},
  year =         2021,
}

@inproceedings{rame2022fishr,
  title =        {Fishr: Invariant Gradient Variances for Out-of-distribution
                  Generalization},
  author =       {Alexandre Rame and Corentin Dancette and Matthieu Cord},
  year =         2022,
  booktitle =    {International Conference on Machine Learning (ICML)}
}

@inproceedings{skorski2021revisiting,
  title =        {Revisiting Weight Initialization of Deep Neural Networks},
  author =       {Skorski, Maciej and Temperoni, Alessandro and Theobald,
                  Martin},
  booktitle =    {Asian Conference on Machine Learning (ACML)},
  year =         2021,
}

@article{shorten2019survey,
  title =        {A survey on image data augmentation for deep learning},
  author =       {Shorten, Connor and Khoshgoftaar, Taghi M},
  journal =      {Journal of big data},
  year =         2019,
}

@article{dangel2022vivit,
  title =        {Vi{V}i{T}: Curvature Access Through The Generalized
                  Gauss-Newton{\textquoteright}s Low-Rank Structure},
  author =       {Felix Dangel and Lukas Tatzel and Philipp Hennig},
  journal =      {Transactions on Machine Learning Research (TMLR)},
  year =         2022,
}
